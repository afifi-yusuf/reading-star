{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install requirements\n",
    "%pip install SpeechRecognition\n",
    "%pip install pyaudio\n",
    "%pip install openvino\n",
    "%pip install openvino-genai\n",
    "%pip install transformers torch librosa numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run to convert and generate whisper into OpenVino\n",
    "# PS: Delete the whisper-tiny folder before pushing changes onto origin\n",
    "\n",
    "\n",
    "import logging\n",
    "import nncf\n",
    "from cmd_helper import optimum_cli\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Set logging level\n",
    "nncf.set_log_level(logging.ERROR)\n",
    "\n",
    "\n",
    "# Define model ID and path\n",
    "model_id = \"openai/whisper-tiny\"\n",
    "model_path = Path(model_id.split(\"/\")[1])\n",
    "\n",
    "\n",
    "# Convert the model using OpenVINO tools\n",
    "optimum_cli(model_id, model_path)\n",
    "print(f\"âœ… {model_id} model converted and can be found in {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main code, has to be ran after the previous 2\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import speech_recognition as sr\n",
    "from datetime import datetime, timedelta\n",
    "from queue import Queue\n",
    "from time import sleep\n",
    "from difflib import SequenceMatcher\n",
    "from transformers import AutoProcessor, AutoModelForSpeechSeq2Seq, pipeline\n",
    "from transformers.utils import logging\n",
    "import openvino_genai as ov_genai\n",
    "from notebook_utils import device_widget\n",
    "import librosa\n",
    "import torch\n",
    "\n",
    "\n",
    "# Select device\n",
    "device = device_widget(default=\"CPU\", exclude=[\"NPU\"])\n",
    "\n",
    "\n",
    "# Initialize OpenVINO pipeline\n",
    "ov_pipe = ov_genai.WhisperPipeline(str(model_path), device=device.value)\n",
    "\n",
    "\n",
    "# Known lyrics and matching function remain the same\n",
    "lyrics = {\n",
    "   \"Verse 1\": [\n",
    "       \"Twinkle, twinkle, little star\",\n",
    "       \"How I wonder what you are\",\n",
    "       \"Up above the world so high\",\n",
    "       \"Like a diamond in the sky\",\n",
    "   ]\n",
    "}\n",
    "\n",
    "\n",
    "def find_closest_match(transcription, lyrics):\n",
    "   best_match = \"\"\n",
    "   highest_similarity = 0\n",
    "   for line in lyrics:\n",
    "       similarity = SequenceMatcher(None, transcription, line).ratio()\n",
    "       if similarity > highest_similarity:\n",
    "           highest_similarity = similarity\n",
    "           best_match = line\n",
    "   return best_match, highest_similarity\n",
    "\n",
    "\n",
    "# Audio recording setup\n",
    "energy_threshold = 1000\n",
    "record_timeout = 2.0\n",
    "phrase_timeout = 3.0\n",
    "phrase_time = None\n",
    "data_queue = Queue()\n",
    "recorder = sr.Recognizer()\n",
    "recorder.energy_threshold = energy_threshold\n",
    "recorder.dynamic_energy_threshold = False\n",
    "\n",
    "\n",
    "source = sr.Microphone(sample_rate=16000)\n",
    "\n",
    "\n",
    "def record_callback(_, audio: sr.AudioData) -> None:\n",
    "   data = audio.get_raw_data()\n",
    "   data_queue.put(data)\n",
    "\n",
    "\n",
    "# Main processing loop\n",
    "with source:\n",
    "   recorder.adjust_for_ambient_noise(source)\n",
    "\n",
    "\n",
    "recorder.listen_in_background(source, record_callback, phrase_time_limit=record_timeout)\n",
    "print(\"Model loaded and microphone initialized.\\n\")\n",
    "\n",
    "\n",
    "try:\n",
    "   current_verse = \"Verse 1\"\n",
    "   while True:\n",
    "       now = datetime.utcnow()\n",
    "       if not data_queue.empty():\n",
    "           if phrase_time and now - phrase_time > timedelta(seconds=phrase_timeout):\n",
    "               phrase_complete = True\n",
    "           phrase_time = now\n",
    "\n",
    "\n",
    "           # Get audio data\n",
    "           audio_data = b''.join(data_queue.queue)\n",
    "           data_queue.queue.clear()\n",
    "\n",
    "\n",
    "           # Convert to numpy array\n",
    "           audio_np = np.frombuffer(audio_data, dtype=np.int16).astype(np.float32) / 32768.0\n",
    "\n",
    "\n",
    "           # Process with OpenVINO pipeline\n",
    "           genai_result = ov_pipe.generate(audio_np)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "           recognized_text = str(genai_result).strip()\n",
    "           # Match with lyrics\n",
    "           match, similarity = find_closest_match(recognized_text, lyrics[current_verse])\n",
    "\n",
    "\n",
    "           # Clear screen and display results\n",
    "           os.system('clear')\n",
    "           print(f\"\\nRecognized: {recognized_text}\")\n",
    "           print(f\"Best Match: {match} (Similarity: {similarity:.2f})\")\n",
    "       else:\n",
    "           sleep(0.25)\n",
    "\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "   print(\"\\nTranscription stopped by user.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
