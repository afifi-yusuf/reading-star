{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SpeechRecognition in ./myenv/lib/python3.11/site-packages (3.13.0)\n",
      "Requirement already satisfied: typing-extensions in ./myenv/lib/python3.11/site-packages (from SpeechRecognition) (4.12.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting pyaudio\n",
      "  Downloading PyAudio-0.2.14.tar.gz (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: pyaudio\n",
      "  Building wheel for pyaudio (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyaudio: filename=PyAudio-0.2.14-cp311-cp311-macosx_10_9_universal2.whl size=39023 sha256=9e6834340906ff737b66370c7af84112d6043b929fd88cbc46f4d35d6ef89c73\n",
      "  Stored in directory: /Users/anthonynkyi/Library/Caches/pip/wheels/80/b1/c1/67e4ef443de2665d86031d4760508094eab5de37d5d64d9c27\n",
      "Successfully built pyaudio\n",
      "Installing collected packages: pyaudio\n",
      "Successfully installed pyaudio-0.2.14\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: openvino in ./myenv/lib/python3.11/site-packages (2024.6.0)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.16.6 in ./myenv/lib/python3.11/site-packages (from openvino) (1.26.4)\n",
      "Requirement already satisfied: openvino-telemetry>=2023.2.1 in ./myenv/lib/python3.11/site-packages (from openvino) (2024.5.0)\n",
      "Requirement already satisfied: packaging in ./myenv/lib/python3.11/site-packages (from openvino) (24.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: openvino-genai in ./myenv/lib/python3.11/site-packages (2024.6.0.0)\n",
      "Requirement already satisfied: openvino_tokenizers~=2024.6.0.0.dev in ./myenv/lib/python3.11/site-packages (from openvino-genai) (2024.6.0.0)\n",
      "Requirement already satisfied: openvino~=2024.6.0.dev in ./myenv/lib/python3.11/site-packages (from openvino_tokenizers~=2024.6.0.0.dev->openvino-genai) (2024.6.0)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.16.6 in ./myenv/lib/python3.11/site-packages (from openvino~=2024.6.0.dev->openvino_tokenizers~=2024.6.0.0.dev->openvino-genai) (1.26.4)\n",
      "Requirement already satisfied: openvino-telemetry>=2023.2.1 in ./myenv/lib/python3.11/site-packages (from openvino~=2024.6.0.dev->openvino_tokenizers~=2024.6.0.0.dev->openvino-genai) (2024.5.0)\n",
      "Requirement already satisfied: packaging in ./myenv/lib/python3.11/site-packages (from openvino~=2024.6.0.dev->openvino_tokenizers~=2024.6.0.0.dev->openvino-genai) (24.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers in ./myenv/lib/python3.11/site-packages (4.46.3)\n",
      "Requirement already satisfied: torch in ./myenv/lib/python3.11/site-packages (2.5.1)\n",
      "Requirement already satisfied: librosa in ./myenv/lib/python3.11/site-packages (0.10.2.post1)\n",
      "Requirement already satisfied: numpy in ./myenv/lib/python3.11/site-packages (1.26.4)\n",
      "Requirement already satisfied: filelock in ./myenv/lib/python3.11/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in ./myenv/lib/python3.11/site-packages (from transformers) (0.27.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./myenv/lib/python3.11/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./myenv/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./myenv/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in ./myenv/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in ./myenv/lib/python3.11/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./myenv/lib/python3.11/site-packages (from transformers) (0.5.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./myenv/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./myenv/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in ./myenv/lib/python3.11/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in ./myenv/lib/python3.11/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in ./myenv/lib/python3.11/site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./myenv/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./myenv/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in ./myenv/lib/python3.11/site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: scipy>=1.2.0 in ./myenv/lib/python3.11/site-packages (from librosa) (1.15.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in ./myenv/lib/python3.11/site-packages (from librosa) (1.6.0)\n",
      "Requirement already satisfied: joblib>=0.14 in ./myenv/lib/python3.11/site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in ./myenv/lib/python3.11/site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in ./myenv/lib/python3.11/site-packages (from librosa) (0.60.0)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in ./myenv/lib/python3.11/site-packages (from librosa) (0.13.0)\n",
      "Requirement already satisfied: pooch>=1.1 in ./myenv/lib/python3.11/site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in ./myenv/lib/python3.11/site-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in ./myenv/lib/python3.11/site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in ./myenv/lib/python3.11/site-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in ./myenv/lib/python3.11/site-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in ./myenv/lib/python3.11/site-packages (from pooch>=1.1->librosa) (4.3.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./myenv/lib/python3.11/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./myenv/lib/python3.11/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./myenv/lib/python3.11/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./myenv/lib/python3.11/site-packages (from requests->transformers) (2024.12.14)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./myenv/lib/python3.11/site-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.0 in ./myenv/lib/python3.11/site-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./myenv/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: pycparser in ./myenv/lib/python3.11/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install requirements\n",
    "%pip install SpeechRecognition\n",
    "%pip install pyaudio\n",
    "%pip install openvino\n",
    "%pip install openvino-genai\n",
    "%pip install transformers torch librosa numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Export command:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "`optimum-cli export openvino --model openai/whisper-base.en whisper-base.en`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Moving the following attributes in the config to the generation config: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 357, 366, 438, 532, 685, 705, 796, 930, 1058, 1220, 1267, 1279, 1303, 1343, 1377, 1391, 1635, 1782, 1875, 2162, 2361, 2488, 3467, 4008, 4211, 4600, 4808, 5299, 5855, 6329, 7203, 9609, 9959, 10563, 10786, 11420, 11709, 11907, 13163, 13697, 13700, 14808, 15306, 16410, 16791, 17992, 19203, 19510, 20724, 22305, 22935, 27007, 30109, 30420, 33409, 34949, 40283, 40493, 40549, 47282, 49146, 50257, 50357, 50358, 50359, 50360, 50361]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n",
      "/Users/anthonynkyi/Documents/cs/COMP0016/reading-star/myenv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py:1017: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if input_features.shape[-1] != expected_seq_length:\n",
      "/Users/anthonynkyi/Documents/cs/COMP0016/reading-star/myenv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py:334: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if attn_output.size() != (bsz, self.num_heads, tgt_len, self.head_dim):\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "/Users/anthonynkyi/Documents/cs/COMP0016/reading-star/myenv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py:1477: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if sequence_length != 1:\n",
      "/Users/anthonynkyi/Documents/cs/COMP0016/reading-star/myenv/lib/python3.11/site-packages/transformers/cache_utils.py:458: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.\n",
      "  or len(self.key_cache[layer_idx]) == 0  # the layer has no cache\n",
      "/Users/anthonynkyi/Documents/cs/COMP0016/reading-star/myenv/lib/python3.11/site-packages/transformers/cache_utils.py:443: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.\n",
      "  elif len(self.key_cache[layer_idx]) == 0:  # fills previously skipped layers; checking for tensor causes errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ openai/whisper-base.en model converted and can be found in whisper-base.en\n"
     ]
    }
   ],
   "source": [
    "# Run to convert and generate whisper into OpenVino\n",
    "# PS: Delete the whisper-tiny folder before pushing changes onto origin\n",
    "\n",
    "\n",
    "import logging\n",
    "import nncf\n",
    "from cmd_helper import optimum_cli\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Set logging level\n",
    "nncf.set_log_level(logging.ERROR)\n",
    "\n",
    "\n",
    "# Define model ID and path\n",
    "model_id = \"openai/whisper-base.en\"\n",
    "model_path = Path(model_id.split(\"/\")[1])\n",
    "\n",
    "\n",
    "# Convert the model using OpenVINO tools\n",
    "optimum_cli(model_id, model_path)\n",
    "print(f\"✅ {model_id} model converted and can be found in {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchaudio in ./myenv/lib/python3.11/site-packages (2.5.1)\n",
      "Requirement already satisfied: torch==2.5.1 in ./myenv/lib/python3.11/site-packages (from torchaudio) (2.5.1)\n",
      "Requirement already satisfied: filelock in ./myenv/lib/python3.11/site-packages (from torch==2.5.1->torchaudio) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./myenv/lib/python3.11/site-packages (from torch==2.5.1->torchaudio) (4.12.2)\n",
      "Requirement already satisfied: networkx in ./myenv/lib/python3.11/site-packages (from torch==2.5.1->torchaudio) (3.3)\n",
      "Requirement already satisfied: jinja2 in ./myenv/lib/python3.11/site-packages (from torch==2.5.1->torchaudio) (3.1.5)\n",
      "Requirement already satisfied: fsspec in ./myenv/lib/python3.11/site-packages (from torch==2.5.1->torchaudio) (2024.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./myenv/lib/python3.11/site-packages (from torch==2.5.1->torchaudio) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./myenv/lib/python3.11/site-packages (from sympy==1.13.1->torch==2.5.1->torchaudio) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./myenv/lib/python3.11/site-packages (from jinja2->torch==2.5.1->torchaudio) (2.1.5)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: mir_eval in ./myenv/lib/python3.11/site-packages (0.7)\n",
      "Requirement already satisfied: numpy>=1.7.0 in ./myenv/lib/python3.11/site-packages (from mir_eval) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.0.0 in ./myenv/lib/python3.11/site-packages (from mir_eval) (1.15.0)\n",
      "Requirement already satisfied: future in ./myenv/lib/python3.11/site-packages (from mir_eval) (1.0.0)\n",
      "Requirement already satisfied: six in ./myenv/lib/python3.11/site-packages (from mir_eval) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pydub in ./myenv/lib/python3.11/site-packages (0.25.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: ffmpeg in ./myenv/lib/python3.11/site-packages (1.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: ffprobe in ./myenv/lib/python3.11/site-packages (0.5)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonynkyi/Documents/cs/COMP0016/reading-star/myenv/lib/python3.11/site-packages/torchaudio/pipelines/_source_separation_pipeline.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample rate: 44100\n"
     ]
    }
   ],
   "source": [
    "# live stripping of vocals from background\n",
    "%pip install torchaudio\n",
    "%pip install mir_eval\n",
    "%pip install pydub\n",
    "%pip install ffmpeg\n",
    "%pip install ffprobe\n",
    "\n",
    "import certifi\n",
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "from IPython.display import Audio\n",
    "from mir_eval import separation\n",
    "from torchaudio.pipelines import HDEMUCS_HIGH_MUSDB_PLUS\n",
    "from torchaudio.transforms import Fade\n",
    "from torchaudio.utils import download_asset\n",
    "\n",
    "os.environ['SSL_CERT_FILE'] = certifi.where()\n",
    "bundle = HDEMUCS_HIGH_MUSDB_PLUS\n",
    "model = bundle.get_model()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "sample_rate = bundle.sample_rate\n",
    "print(f\"Sample rate: {sample_rate}\")\n",
    "\n",
    "def separate_sources(\n",
    "    model,\n",
    "    mix,\n",
    "    segment=10.0,\n",
    "    overlap=0.1,\n",
    "    device=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Apply model to a given mixture. Use fade, and add segments together in order to add model segment by segment.\n",
    "\n",
    "    Args:\n",
    "        segment (int): segment length in seconds\n",
    "        device (torch.device, str, or None): if provided, device on which to\n",
    "            execute the computation, otherwise `mix.device` is assumed.\n",
    "            When `device` is different from `mix.device`, only local computations will\n",
    "            be on `device`, while the entire tracks will be stored on `mix.device`.\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = mix.device\n",
    "    else:\n",
    "        device = torch.device(device)\n",
    "\n",
    "    batch, channels, length = mix.shape\n",
    "\n",
    "    chunk_len = int(sample_rate * segment * (1 + overlap))\n",
    "    start = 0\n",
    "    end = chunk_len\n",
    "    overlap_frames = overlap * sample_rate\n",
    "    fade = Fade(fade_in_len=0, fade_out_len=int(overlap_frames), fade_shape=\"linear\")\n",
    "\n",
    "    final = torch.zeros(batch, len(model.sources), channels, length, device=device)\n",
    "\n",
    "    while start < length - overlap_frames:\n",
    "        chunk = mix[:, :, start:end]\n",
    "        with torch.no_grad():\n",
    "            out = model.forward(chunk)\n",
    "        out = fade(out)\n",
    "        final[:, :, :, start:end] += out\n",
    "        if start == 0:\n",
    "            fade.fade_in_len = int(overlap_frames)\n",
    "            start += int(chunk_len - overlap_frames)\n",
    "        else:\n",
    "            start += chunk_len\n",
    "        end += chunk_len\n",
    "        if end >= length:\n",
    "            fade.fade_out_len = 0\n",
    "    return final\n",
    "\n",
    "\n",
    "def plot_spectrogram(stft, title=\"Spectrogram\"):\n",
    "    magnitude = stft.abs()\n",
    "    spectrogram = 20 * torch.log10(magnitude + 1e-8).numpy()\n",
    "    _, axis = plt.subplots(1, 1)\n",
    "    axis.imshow(spectrogram, cmap=\"viridis\", vmin=-60, vmax=0, origin=\"lower\", aspect=\"auto\")\n",
    "    axis.set_title(title)\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded and microphone initialized.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h_/lg0zhls57_l_8r2q6kbmsszw0000gn/T/ipykernel_68445/2736584775.py:98: RuntimeWarning: divide by zero encountered in divide\n",
      "  normalized_waveform = (normalized_waveform - ref.mean()) / ref.std()  # normalization\n",
      "/var/folders/h_/lg0zhls57_l_8r2q6kbmsszw0000gn/T/ipykernel_68445/2736584775.py:98: RuntimeWarning: invalid value encountered in divide\n",
      "  normalized_waveform = (normalized_waveform - ref.mean()) / ref.std()  # normalization\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 101\u001b[0m\n\u001b[1;32m     98\u001b[0m normalized_waveform \u001b[38;5;241m=\u001b[39m (normalized_waveform \u001b[38;5;241m-\u001b[39m ref\u001b[38;5;241m.\u001b[39mmean()) \u001b[38;5;241m/\u001b[39m ref\u001b[38;5;241m.\u001b[39mstd()  \u001b[38;5;66;03m# normalization\u001b[39;00m\n\u001b[1;32m     99\u001b[0m normalized_waveform \u001b[38;5;241m=\u001b[39m normalized_waveform\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m--> 101\u001b[0m sources \u001b[38;5;241m=\u001b[39m \u001b[43mseparate_sources\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnormalized_waveform\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43msegment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverlap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\n\u001b[1;32m    107\u001b[0m \u001b[43m \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    109\u001b[0m sources_list \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39msources\n\u001b[1;32m    110\u001b[0m sources \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(sources)\n",
      "Cell \u001b[0;32mIn[11], line 49\u001b[0m, in \u001b[0;36mseparate_sources\u001b[0;34m(model, mix, segment, overlap, device)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m     device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(device)\n\u001b[0;32m---> 49\u001b[0m batch, channels, length \u001b[38;5;241m=\u001b[39m mix\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     51\u001b[0m chunk_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(sample_rate \u001b[38;5;241m*\u001b[39m segment \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m overlap))\n\u001b[1;32m     52\u001b[0m start \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "# Main code, has to be ran after the previous 2\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import speech_recognition as sr\n",
    "from datetime import datetime, timedelta\n",
    "from queue import Queue\n",
    "from time import sleep\n",
    "from difflib import SequenceMatcher\n",
    "from transformers import AutoProcessor, AutoModelForSpeechSeq2Seq, pipeline\n",
    "from transformers.utils import logging\n",
    "import openvino_genai as ov_genai\n",
    "from notebook_utils import device_widget\n",
    "import librosa\n",
    "import torch\n",
    "\n",
    "\n",
    "# Select device\n",
    "device = device_widget(default=\"CPU\", exclude=[\"NPU\"])\n",
    "\n",
    "\n",
    "# Initialize OpenVINO pipeline\n",
    "ov_pipe = ov_genai.WhisperPipeline(str(model_path), device=device.value)\n",
    "\n",
    "\n",
    "# Known lyrics and matching function remain the same\n",
    "lyrics = {\n",
    "   \"Verse 1\": [\n",
    "       \"Twinkle, twinkle, little star\",\n",
    "       \"How I wonder what you are\",\n",
    "       \"Up above the world so high\",\n",
    "       \"Like a diamond in the sky\",\n",
    "   ]\n",
    "}\n",
    "\n",
    "\n",
    "def find_closest_match(transcription, lyrics):\n",
    "   best_match = \"\"\n",
    "   highest_similarity = 0\n",
    "   for line in lyrics:\n",
    "       similarity = SequenceMatcher(None, transcription, line).ratio()\n",
    "       if similarity > highest_similarity:\n",
    "           highest_similarity = similarity\n",
    "           best_match = line\n",
    "   return best_match, highest_similarity\n",
    "\n",
    "\n",
    "# Audio recording setup\n",
    "energy_threshold = 1000\n",
    "record_timeout = 3.0\n",
    "phrase_timeout = 3.0\n",
    "phrase_time = None\n",
    "data_queue = Queue()\n",
    "recorder = sr.Recognizer()\n",
    "recorder.energy_threshold = energy_threshold\n",
    "recorder.dynamic_energy_threshold = False\n",
    "\n",
    "\n",
    "source = sr.Microphone(sample_rate=16000)\n",
    "\n",
    "\n",
    "def record_callback(_, audio: sr.AudioData) -> None:\n",
    "   data = audio.get_raw_data()\n",
    "   data_queue.put(data)\n",
    "\n",
    "\n",
    "# Main processing loop\n",
    "with source:\n",
    "   recorder.adjust_for_ambient_noise(source)\n",
    "\n",
    "\n",
    "stop_call = recorder.listen_in_background(source, record_callback, phrase_time_limit=record_timeout)\n",
    "print(\"Model loaded and microphone initialized.\\n\")\n",
    "\n",
    "t = np.linspace(0, 1, 16000, endpoint=False)\n",
    "frequency = 440  # A4 note\n",
    "\n",
    "try:\n",
    "   current_verse = \"Verse 1\"\n",
    "   while True:\n",
    "       now = datetime.utcnow()\n",
    "       if not data_queue.empty():\n",
    "           if phrase_time and now - phrase_time > timedelta(seconds=phrase_timeout):\n",
    "               phrase_complete = True\n",
    "           phrase_time = now\n",
    "\n",
    "           # Get audio data\n",
    "           audio_data = b''.join(data_queue.queue)\n",
    "           data_queue.queue.clear()\n",
    "\n",
    "           # Convert to numpy array\n",
    "           audio_np = np.frombuffer(audio_data, dtype=np.int16).astype(np.float32) / 32768.0\n",
    "           waveform = 0.5 * np.sin(2 * np.pi * frequency * t)\n",
    "           normalized_waveform = np.int16(waveform / np.max(np.abs(waveform)) * 32767)\n",
    "\n",
    "           ref = normalized_waveform.mean(0)\n",
    "           normalized_waveform = (normalized_waveform - ref.mean()) / ref.std()  # normalization\n",
    "           normalized_waveform = normalized_waveform.astype(np.float32)\n",
    "\n",
    "           sources = separate_sources(\n",
    "               model, \n",
    "               mix=normalized_waveform[None], \n",
    "               device=\"cpu\",\n",
    "               segment=1,\n",
    "               overlap=0.1\n",
    "            )[0]\n",
    "           \n",
    "           sources_list = model.sources\n",
    "           sources = list(sources)\n",
    "           audios = dict(zip(sources_list, sources))\n",
    "           \n",
    "           # Display audio sources\n",
    "           vocals = audios[\"vocals\"].cpu()\n",
    "\n",
    "           # Process with OpenVINO pipeline\n",
    "           genai_result = ov_pipe.generate(vocals)\n",
    "\n",
    "           recognized_text = str(genai_result).strip()\n",
    "           # Match with lyrics\n",
    "           match, similarity = find_closest_match(recognized_text, lyrics[current_verse])\n",
    "\n",
    "           # Clear screen and display results\n",
    "           os.system('clear')\n",
    "           print(f\"\\nRecognized: {recognized_text}\")\n",
    "           print(f\"Best Match: {match} (Similarity: {similarity:.2f})\")\n",
    "       else:\n",
    "           sleep(0.1)\n",
    "\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "   print(\"\\nTranscription stopped by user.\")\n",
    "   stop_call()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
